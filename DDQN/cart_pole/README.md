# Cart Pole
I used the cart pole environment as a way to test my DDQN implementation before moving on to more interesting, higher dimensional environments.

# Results
This is the agent's score per episode as it learns a control policy for the cart pole environment. Solving the environment is considered getting an average score of 190 or more for over 100 continous episodes. Below is a visualization of the agent's progress under one set of hyper-parameters. Then, underneath is another visualization under another set of hyper-parameters. I was surprised how sensitive the algorithm is to the hyper-parameters. 
![Agent's Progress](images/reward_time.png)


![Agent's Progress](images/reward_time2.png)

Add a gif of the learned policy
